{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce46ecd-5369-42fd-bb5d-39eac14cc688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project2/alvinjin_1630\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/project2/alvinjin_1630/results')\n",
    "\n",
    "from Trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ae46cd-5d5a-48b0-a059-a8b7ee59c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch sees: 1 GPUs, NVIDIA A100-PCIE-40GB\n",
      "JAX sees: [CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import torch, jax\n",
    "print(\"PyTorch sees:\", torch.cuda.device_count(), \"GPUs,\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"none\")\n",
    "print(\"JAX sees:\", jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db538fe5-db99-4054-807c-836f9c7604ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optuna dashboard on http://localhost:8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.13.4 server starting up (using WSGIRefServer())...\n",
      "Listening on http://0.0.0.0:8080/\n",
      "Hit Ctrl-C to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the following command in your local terminal on YOUR MACHINE, not in the cluster:\n",
      "ssh -L 8080:a01-15.hpc.usc.edu:8080 {YOUR USERNAME}@discovery.usc.edu\n",
      "Once you enter the cluster from your terminal, navigate to http://localhost:8080 in a web browser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10.125.0.217 - - [28/Sep/2025 17:30:26] \"GET / HTTP/1.1\" 302 0\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:26] \"GET /api/studies HTTP/1.1\" 200 2705\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:37] \"GET /api/studies/24/param_importances?evaluator=ped_anova HTTP/1.1\" 200 27\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:37] \"GET /api/studies/24?after=0 HTTP/1.1\" 200 7370\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:37] \"GET /api/meta HTTP/1.1\" 200 64\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:37] \"GET /api/studies/24/param_importances?evaluator=ped_anova HTTP/1.1\" 200 27\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:39] \"GET /api/studies/24?after=3 HTTP/1.1\" 200 2959\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:40] \"GET /api/studies HTTP/1.1\" 200 2705\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:40] \"GET /api/studies/25/param_importances?evaluator=ped_anova HTTP/1.1\" 200 27\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:40] \"GET /api/studies/25?after=0 HTTP/1.1\" 200 2790\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:40] \"GET /api/meta HTTP/1.1\" 200 64\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:43] \"GET /api/studies/25?after=0 HTTP/1.1\" 200 2790\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:46] \"GET /api/studies/25?after=0 HTTP/1.1\" 200 2790\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:49] \"GET /api/studies/25?after=0 HTTP/1.1\" 200 2790\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:52] \"GET /api/studies/25?after=0 HTTP/1.1\" 200 2790\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:55] \"GET /api/studies/25?after=0 HTTP/1.1\" 200 2790\n",
      "10.125.0.217 - - [28/Sep/2025 17:30:58] \"GET /api/studies/25?after=0 HTTP/1.1\" 200 2790\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:01] \"GET /api/studies/25?after=0 HTTP/1.1\" 200 2838\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:04] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:07] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:10] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:13] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:16] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:19] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:22] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:25] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:28] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:31] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:34] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:37] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:40] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:43] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:46] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:49] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:52] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:54] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:56] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:31:59] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n",
      "10.125.0.217 - - [28/Sep/2025 17:32:02] \"GET /api/studies/25?after=1 HTTP/1.1\" 200 1370\n"
     ]
    }
   ],
   "source": [
    "Trainer.start_optuna_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b1e717-daef-4c52-b858-de416aa8e2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 17:30:10,920] A new study created in RDB with name: D1_50x9_relu_no_res\n",
      "/home1/adshaw/.local/lib/python3.13/site-packages/equinox/nn/_normalisation.py:92: UserWarning: LayerNorm(elementwise_affine=...) is deprecated in favour of LayerNorm(use_weight=...) and LayerNorm(use_bias=...)\n",
      "  warnings.warn(\n",
      "2025-09-28 17:31:00.871271: W external/xla/xla/stream_executor/cuda/cuda_command_buffer.cc:668] Retry CUDA graph instantiation after OOM error\n",
      "E0928 17:31:00.874382 3666951 pjrt_stream_executor_client.cc:3077] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Underlying backend ran out of memory trying to instantiate graph with 1851 nodes and 0 conditionals (total of 0 alive graphs in the process). You can try to (a) Give more memory to the driver by reducing XLA_CLIENT_MEM_FRACTION (b) Disable command buffers with 'XLA_FLAGS=--xla_gpu_enable_command_buffer=' (empty set). Original error: Failed to instantiate CUDA graph: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[W 2025-09-28 17:31:00,896] Trial 0 failed with parameters: {'lr_w': 5.05e-05, 'lr_h': 0.003109, 'trans_mult': 9.332, 'decay_rate': 0.9766} because of the following error: XlaRuntimeError(\"RESOURCE_EXHAUSTED: Underlying backend ran out of memory trying to instantiate graph with 1851 nodes and 0 conditionals (total of 0 alive graphs in the process). You can try to (a) Give more memory to the driver by reducing XLA_CLIENT_MEM_FRACTION (b) Disable command buffers with 'XLA_FLAGS=--xla_gpu_enable_command_buffer=' (empty set). Original error: Failed to instantiate CUDA graph: CUDA_ERROR_OUT_OF_MEMORY: out of memory\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/adshaw/.local/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/project2/alvinjin_1630/results/Trainer.py\", line 539, in objective\n",
      "    train(train_loader, T=T, model=model, optim_w=optim_w, optim_h=optim_h)\n",
      "    ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/project2/alvinjin_1630/results/Trainer.py\", line 253, in train\n",
      "    train_on_batch(T, x_jax, jax.nn.one_hot(y_jax, model.output_dim.get()), model=model, optim_w=optim_w, optim_h=optim_h)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home1/adshaw/.local/lib/python3.13/site-packages/pcx/functional/_transform.py\", line 175, in __call__\n",
      "    _r, _kwargs = self._t(*args, **kwargs)\n",
      "                  ~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home1/adshaw/.local/lib/python3.13/site-packages/pcx/functional/_transform.py\", line 260, in _t\n",
      "    _r, kwargs = self.wrap_fn(*args, **kwargs)\n",
      "                 ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/home1/adshaw/.local/lib/python3.13/site-packages/jax/_src/traceback_util.py\", line 180, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/home1/adshaw/.local/lib/python3.13/site-packages/jax/_src/pjit.py\", line 339, in cache_miss\n",
      "    pgle_profiler) = _python_pjit_helper(fun, jit_info, *args, **kwargs)\n",
      "                     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home1/adshaw/.local/lib/python3.13/site-packages/jax/_src/pjit.py\", line 194, in _python_pjit_helper\n",
      "    out_flat, compiled, profiler = _pjit_call_impl_python(*args_flat, **p.params)\n",
      "                                   ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home1/adshaw/.local/lib/python3.13/site-packages/jax/_src/pjit.py\", line 1681, in _pjit_call_impl_python\n",
      "    return compiled.unsafe_call(*args), compiled, pgle_profiler\n",
      "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/home1/adshaw/.local/lib/python3.13/site-packages/jax/_src/profiler.py\", line 334, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home1/adshaw/.local/lib/python3.13/site-packages/jax/_src/interpreters/pxla.py\", line 1297, in __call__\n",
      "    results = self.xla_executable.execute_sharded(input_bufs)\n",
      "jaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Underlying backend ran out of memory trying to instantiate graph with 1851 nodes and 0 conditionals (total of 0 alive graphs in the process). You can try to (a) Give more memory to the driver by reducing XLA_CLIENT_MEM_FRACTION (b) Disable command buffers with 'XLA_FLAGS=--xla_gpu_enable_command_buffer=' (empty set). Original error: Failed to instantiate CUDA graph: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[W 2025-09-28 17:31:00,899] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Underlying backend ran out of memory trying to instantiate graph with 1851 nodes and 0 conditionals (total of 0 alive graphs in the process). You can try to (a) Give more memory to the driver by reducing XLA_CLIENT_MEM_FRACTION (b) Disable command buffers with 'XLA_FLAGS=--xla_gpu_enable_command_buffer=' (empty set). Original error: Failed to instantiate CUDA graph: CUDA_ERROR_OUT_OF_MEMORY: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXlaRuntimeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m trainer = Trainer(\n\u001b[32m      2\u001b[39m     dataset=\u001b[33m'\u001b[39m\u001b[33mD1\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m     hidden_dims=[\u001b[32m50\u001b[39m]*\u001b[32m9\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     residual=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_optuna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mT_func\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m35\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_lr_w_func\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr_w\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_lr_h_func\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr_h\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrans_mult_func\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrans_mult\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecay_rate_func\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdecay_rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.85\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.99\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr_w\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5.050e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr_h\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3.109e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrans_mult\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m9.332\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdecay_rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.9766\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/project2/alvinjin_1630/results/Trainer.py:583\u001b[39m, in \u001b[36mTrainer.run_optuna\u001b[39m\u001b[34m(self, num_models, T_func, start_lr_w_func, start_lr_h_func, trans_mult_func, decay_rate_func, early_stopping, add_trials)\u001b[39m\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m add_trials:\n\u001b[32m    581\u001b[39m         study.enqueue_trial(trial)\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/optuna/study/_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/project2/alvinjin_1630/results/Trainer.py:539\u001b[39m, in \u001b[36mTrainer.run_optuna.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_epochs):\n\u001b[32m    538\u001b[39m     train_loader = \u001b[38;5;28mself\u001b[39m.get_epoch_dataloader(i, epoch, train_sub)\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m=\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_w\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptim_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_h\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptim_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    541\u001b[39m     test_acc, _ = \u001b[38;5;28meval\u001b[39m(test_loader, model=model)\n\u001b[32m    542\u001b[39m     best_test_acc = \u001b[38;5;28mmax\u001b[39m(best_test_acc, test_acc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/project2/alvinjin_1630/results/Trainer.py:253\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dl, T, model, optim_w, optim_h)\u001b[39m\n\u001b[32m    251\u001b[39m x_jax = jnp.asarray(x_flat)\n\u001b[32m    252\u001b[39m y_jax = jnp.asarray(y)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_jax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_jax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_w\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptim_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_h\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptim_h\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pcx/functional/_transform.py:175\u001b[39m, in \u001b[36m_BaseTransform.__call__\u001b[39m\u001b[34m(self, _is_root, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_root \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    174\u001b[39m     kwargs = tree_ref(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m _r, _kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# This is the key part: the updated values are injected back into the original parameters in 'kwargs'. 'kwargs'\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# is still the original structure as it hasn't undergone any transformation (which happens only inside '_t').\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# The update values are obtained by calling 'extract', which is done automatically by the wrapped 'fn'.\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# If 'tree_extract' is called before returning '_kwargs', a list of value was returned, so we tell 'tree_inject'\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# to handle it correctly.\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pcx/functional/_transform.py:260\u001b[39m, in \u001b[36mJit._t\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_t\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     _r, kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrap_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _r, kwargs\n",
      "    \u001b[31m[... skipping hidden 5 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/jax/_src/interpreters/pxla.py:1297\u001b[39m, in \u001b[36mExecuteReplicated.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1295\u001b[39m   \u001b[38;5;28mself\u001b[39m._handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m   results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mxla_executable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dispatch.needs_check_special():\n\u001b[32m   1300\u001b[39m   out_arrays = results.disassemble_into_single_device_arrays()\n",
      "\u001b[31mXlaRuntimeError\u001b[39m: RESOURCE_EXHAUSTED: Underlying backend ran out of memory trying to instantiate graph with 1851 nodes and 0 conditionals (total of 0 alive graphs in the process). You can try to (a) Give more memory to the driver by reducing XLA_CLIENT_MEM_FRACTION (b) Disable command buffers with 'XLA_FLAGS=--xla_gpu_enable_command_buffer=' (empty set). Original error: Failed to instantiate CUDA graph: CUDA_ERROR_OUT_OF_MEMORY: out of memory"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    dataset='D1',\n",
    "    hidden_dims=[50]*9,\n",
    "    act_fn=jax.nn.relu,\n",
    "    study_name='50x9_relu_no_res',\n",
    "    residual=False\n",
    ")\n",
    "\n",
    "trainer.run_optuna(\n",
    "    num_models=3,\n",
    "    T_func=lambda trial: 35,\n",
    "    start_lr_w_func=lambda trial: trial.suggest_float('lr_w', 8e-6, 4e-4, log=True),\n",
    "    start_lr_h_func=lambda trial: trial.suggest_float('lr_h', 8e-4, 5e-2, log=True),\n",
    "    trans_mult_func=lambda trial: trial.suggest_float('trans_mult', 6, 20),\n",
    "    decay_rate_func=lambda trial: trial.suggest_float('decay_rate', 0.85, 0.99),\n",
    "    add_trials=[{'lr_w': 5.050e-5, 'lr_h': 3.109e-3, 'trans_mult': 9.332, 'decay_rate': 0.9766}]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
