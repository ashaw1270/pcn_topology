{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a323334-1326-468a-9653-d99044750220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project2/alvinjin_1630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/jli99757/.local/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/project2/alvinjin_1630/results')\n",
    "\n",
    "from Trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096c84aa-3795-4bd4-8d89-27d26b862c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch sees: 1 GPUs, Tesla P100-PCIE-16GB\n",
      "JAX sees: [CudaDevice(id=0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/jli99757/.local/lib/python3.13/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 Tesla P100-PCIE-16GB which is of cuda capability 6.0.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/home1/jli99757/.local/lib/python3.13/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
      "/home1/jli99757/.local/lib/python3.13/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
      "Tesla P100-PCIE-16GB with CUDA capability sm_60 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
      "If you want to use the Tesla P100-PCIE-16GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch, jax\n",
    "print(\"PyTorch sees:\", torch.cuda.device_count(), \"GPUs,\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"none\")\n",
    "print(\"JAX sees:\", jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f92c1-29f4-42d6-b99d-fb7f1648f64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 08:39:50,611] A new study created in RDB with name: D1_30_25_20_15_10x4_tanh\n",
      "/home1/jli99757/.local/lib/python3.13/site-packages/equinox/nn/_normalisation.py:92: UserWarning: LayerNorm(elementwise_affine=...) is deprecated in favour of LayerNorm(use_weight=...) and LayerNorm(use_bias=...)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(  \n",
    "    dataset='D1',\n",
    "    hidden_dims=[30, 25, 20, 15, 10, 10, 10, 10],\n",
    "    act_fn=jax.nn.tanh,\n",
    "    study_name='30_25_20_15_10x4_tanh',\n",
    "    residual=False\n",
    ")\n",
    "# run optuna first stop when the accuracy is 98%\n",
    "trainer.run_optuna(\n",
    "    num_models=3,\n",
    "    T_func=lambda trial: 30,\n",
    "    start_lr_w_func=lambda trial: trial.suggest_float('lr_w', 1e-6, 5e-3, log=True),\n",
    "    start_lr_h_func=lambda trial: trial.suggest_float('lr_h', 1e-4, 8e-2, log=True),\n",
    "    trans_mult_func=lambda trial: trial.suggest_float('trans_mult', 3, 20),\n",
    "    decay_rate_func=lambda trial: trial.suggest_float('decay_rate', 0.85, 0.99),\n",
    "    add_trials=[{'lr_w': 9.455e-5, 'lr_h': 4.999e-2, 'trans_mult': 8.779, 'decay_rate': 0.9166}]\n",
    ")\n",
    "\n",
    "# trainer.train_all_models(\n",
    "#     T=30,\n",
    "#     start_lr_w = 0.0001187,\n",
    "#     start_lr_h = 0.07993,\n",
    "#     trans_mult = 8.277,\n",
    "#     decay_rate = 0.9234,\n",
    "#     # model_ids=range(3, 40)\n",
    "# )\n",
    "\n",
    "# trainer.run_ripser()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.3 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
