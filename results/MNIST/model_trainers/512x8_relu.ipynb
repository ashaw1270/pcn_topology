{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cf25cb5-e8c8-4276-be61-4c47f3b6900e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project2/alvinjin_1630\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/project2/alvinjin_1630/results')\n",
    "\n",
    "from Trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c6e9e8-a292-498c-9447-146d5360e768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch sees: 1 GPUs, NVIDIA A100-PCIE-40GB\n",
      "JAX sees: [CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import torch, jax\n",
    "print(\"PyTorch sees:\", torch.cuda.device_count(), \"GPUs,\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"none\")\n",
    "print(\"JAX sees:\", jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f98fed-169b-4029-98a3-32214a2eaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer.start_optuna_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589ad7bb-5f72-4164-a1cb-3f651915f7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/adshaw/.local/lib/python3.13/site-packages/equinox/nn/_normalisation.py:92: UserWarning: LayerNorm(elementwise_affine=...) is deprecated in favour of LayerNorm(use_weight=...) and LayerNorm(use_bias=...)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.9082531929016113\n",
      "Epoch 1: 0.9517227411270142\n",
      "Epoch 0: 0.8782051205635071\n",
      "Epoch 1: 0.9427083134651184\n",
      "Epoch 2: 0.9468148946762085\n",
      "Epoch 3: 0.9518229365348816\n",
      "Epoch 0: 0.9247796535491943\n",
      "Epoch 1: 0.9521234035491943\n",
      "Epoch 0: 0.9230769276618958\n",
      "Epoch 1: 0.9479166865348816\n",
      "Epoch 2: 0.9550280570983887\n",
      "Epoch 0: 0.9345953464508057\n",
      "Epoch 1: 0.9485176205635071\n",
      "Epoch 2: 0.9565304517745972\n",
      "Epoch 0: 0.9322916865348816\n",
      "Epoch 1: 0.9474158883094788\n",
      "Epoch 2: 0.9550280570983887\n",
      "Epoch 0: 0.9284855723381042\n",
      "Epoch 1: 0.9505208134651184\n",
      "Epoch 0: 0.9118589758872986\n",
      "Epoch 1: 0.9479166865348816\n",
      "Epoch 2: 0.94921875\n",
      "Epoch 3: 0.9515224099159241\n",
      "Epoch 0: 0.9309895634651184\n",
      "Epoch 1: 0.9554286599159241\n",
      "Epoch 0: 0.9341946840286255\n",
      "Epoch 1: 0.9489182829856873\n",
      "Epoch 2: 0.9544270634651184\n",
      "Epoch 0: 0.9236778616905212\n",
      "Epoch 1: 0.9525240659713745\n",
      "Epoch 0: 0.921875\n",
      "Epoch 1: 0.9467147588729858\n",
      "Epoch 2: 0.9518229365348816\n",
      "Epoch 0: 0.91015625\n",
      "Epoch 1: 0.9511218070983887\n",
      "Epoch 0: 0.8999398946762085\n",
      "Epoch 1: 0.9388020634651184\n",
      "Epoch 2: 0.9495192170143127\n",
      "Epoch 3: 0.9479166865348816\n",
      "Epoch 4: 0.9591346383094788\n",
      "Epoch 0: 0.9284855723381042\n",
      "Epoch 1: 0.9485176205635071\n",
      "Epoch 2: 0.9445112347602844\n",
      "Epoch 3: 0.9572315812110901\n",
      "Epoch 0: 0.9267828464508057\n",
      "Epoch 1: 0.9442107081413269\n",
      "Epoch 2: 0.9507211446762085\n",
      "Epoch 0: 0.9198718070983887\n",
      "Epoch 1: 0.9507211446762085\n",
      "Epoch 0: 0.9185696840286255\n",
      "Epoch 1: 0.9510216116905212\n",
      "Epoch 0: 0.9073517918586731\n",
      "Epoch 1: 0.9466145634651184\n",
      "Epoch 2: 0.9537259340286255\n",
      "Epoch 0: 0.9278846383094788\n",
      "Epoch 1: 0.9440104365348816\n",
      "Epoch 2: 0.9564303159713745\n",
      "Epoch 0: 0.9215745329856873\n",
      "Epoch 1: 0.9464142918586731\n",
      "Epoch 2: 0.9473156929016113\n",
      "Epoch 3: 0.9476161599159241\n",
      "Epoch 4: 0.9547275900840759\n",
      "Epoch 0: 0.9027444124221802\n",
      "Epoch 1: 0.9364984035491943\n",
      "Epoch 2: 0.9503205418586731\n",
      "Epoch 0: 0.8996394276618958\n",
      "Epoch 1: 0.9451121687889099\n",
      "Epoch 2: 0.9497195482254028\n",
      "Epoch 3: 0.9549278616905212\n",
      "Epoch 0: 0.9276843070983887\n",
      "Epoch 1: 0.9491186141967773\n",
      "Epoch 2: 0.9564303159713745\n",
      "Epoch 0: 0.9350961446762085\n",
      "Epoch 1: 0.9453125\n",
      "Epoch 2: 0.9529246687889099\n",
      "Epoch 0: 0.917067289352417\n",
      "Epoch 1: 0.9393028616905212\n",
      "Epoch 2: 0.948317289352417\n",
      "Epoch 3: 0.9530248641967773\n",
      "Epoch 0: 0.9143629670143127\n",
      "Epoch 1: 0.9410055875778198\n",
      "Epoch 2: 0.9513221383094788\n",
      "Epoch 0: 0.9386017918586731\n",
      "Epoch 1: 0.9487179517745972\n",
      "Epoch 2: 0.9500200152397156\n",
      "Epoch 0: 0.9349960088729858\n",
      "Epoch 1: 0.9427083134651184\n",
      "Epoch 2: 0.9436097741127014\n",
      "Epoch 3: 0.9510216116905212\n",
      "Epoch 0: 0.91796875\n",
      "Epoch 1: 0.9475160241127014\n",
      "Epoch 2: 0.9446113705635071\n",
      "Epoch 3: 0.9513221383094788\n",
      "Epoch 0: 0.9222756624221802\n",
      "Epoch 1: 0.9457131624221802\n",
      "Epoch 2: 0.952223539352417\n",
      "Epoch 0: 0.9231770634651184\n",
      "Epoch 1: 0.9473156929016113\n",
      "Epoch 2: 0.9495192170143127\n",
      "Epoch 3: 0.9566305875778198\n",
      "Epoch 0: 0.9288862347602844\n",
      "Epoch 1: 0.9513221383094788\n",
      "Epoch 0: 0.9122596383094788\n",
      "Epoch 1: 0.9454126358032227\n",
      "Epoch 2: 0.9435096383094788\n",
      "Epoch 3: 0.9475160241127014\n",
      "Epoch 4: 0.9430088400840759\n",
      "Epoch 5: 0.9436097741127014\n",
      "Epoch 6: 0.95703125\n",
      "Epoch 0: 0.9158653616905212\n",
      "Epoch 1: 0.9471153616905212\n",
      "Epoch 2: 0.9495192170143127\n",
      "Epoch 3: 0.9556289911270142\n",
      "Epoch 0: 0.9303886294364929\n",
      "Epoch 1: 0.9428085088729858\n",
      "Epoch 2: 0.9536257982254028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    dataset='MNIST',\n",
    "    hidden_dims=[512]*8,\n",
    "    act_fn=jax.nn.relu,\n",
    "    study_name='512x8_relu',\n",
    "    num_epochs=50,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# trainer.run_optuna(\n",
    "#     num_models=3,\n",
    "#     T_func=lambda trial: 30,\n",
    "#     start_lr_w_func=lambda trial: trial.suggest_float('lr_w', 1e-6, 5e-3, log=True),\n",
    "#     start_lr_h_func=lambda trial: trial.suggest_float('lr_h', 1e-4, 8e-2, log=True),\n",
    "#     trans_mult_func=lambda trial: trial.suggest_float('trans_mult', 1, 10),\n",
    "#     decay_rate_func=lambda trial: trial.suggest_float('decay_rate', 0.85, 0.995),\n",
    "#     early_stopping_within_key=None,\n",
    "#     early_stopping_whole_trial=None,\n",
    "#     add_trials=[\n",
    "#         {'lr_w': 5.531e-5, 'lr_h': 5.670e-2, 'trans_mult': 8.954, 'decay_rate': 0.8548}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "trainer.train_all_models(\n",
    "    T=30,\n",
    "    start_lr_w=5.531e-5,\n",
    "    start_lr_h=5.670e-2,\n",
    "    trans_mult=8.954,\n",
    "    decay_rate=0.8548,\n",
    "    early_stopping=lambda epoch, test_acc: test_acc >= 0.95\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
